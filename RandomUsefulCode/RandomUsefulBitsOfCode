Text manipulation that I find handy for files I work with (last update 9 June 2016):

for i in $(seq -w 01 1 016); do echo "$i"; done
#This will pad a 0 in front of your letters in a sequence (good for when you get sequencing files back...)

split -l NUMBER -d --additional-suffix=.fasta FILE
#splits FILE into smaller files with NUMBER lines each and appends ".fasta" on each one

awk '($1<VALUE1) && ($1>VALUE2) {print}' file
#Finds all occurrences of values in between VALUE1 and VALUE2 in column 1 (hence $1) in file

awk 'NR==NUMBER{print;exit}'
#Print the NUMBER-th line in a file.

awk '{ total += $1 } END { print total/NR }' FILE
#Find the average of a column (here column 1 b/c $1 is given) in FILE - credit to http://stackoverflow.com/questions/3122442/how-do-i-calculate-the-mean-of-a-column

sed 's/[_].*$//' INFILE > OUTFILE
# Removes everything including and after the underscore in a file and prints to a new file

sed 's/^.*[_]//' INFILE > OUTFILE
# Removes everything before a CHARACTER in INFILE and prints to OUTFILE

sed -i 's/ThingToReplace/ThingYouReplaceWith/g' file
# Classic find/replace (-i flag will do it inside file. If you don't want that, leave the -i off and redirect)

grep -A1 'STRING' file
# Prints the line that STRING occurs on and the line following it (good for pulling FASTA files apart using specific criteria in sequence names)
#Use combo of -A# and -B# to pull apart fastq files as well

awk 'NR%4 == 2 {lengths[length($0)]++} END {for (l in lengths) {print l, lengths[l]}}' FILE.fastq
# Prints the read length followed by the number of reads at that length (fastq files). Credit: https://www.biostars.org/p/72433/

awk '{/>/&&++a||b+=length()}END{print b/a}' file.fasta
# Prints average seq lengths (fasta). Credit: https://www.biostars.org/p/1758/

date +"%m/%d/%Y %H:%M:%S this finally finished"
#Prints the timestamp followed by "this finally finished"

tar -zxvf file.tar.gz
# Unzip tar.gz file (I'll never stop googling this).

samtools view INFILE.bam | awk '{OFS="\t"; print ">"$1"\n"$10}' - > INFILE.fasta 
#Conversion of bam file to fasta following Gabriel's post on http://seqanswers.com/forums/archive/index.php/t-6169.html

sed -e 's/\(^>.*$\)/#\1#/' INFILE.fasta | tr -d "\r" | tr -d "\n" | sed -e 's/$/#/' | tr "#" "\n" | sed -e '/^$/d' > INFILE.NOWRAP.fasta 
#Removes word wrapping in Fasta formatted files. NEED TO FIND WHO I STOLE THIS FROM AND ADD IT HERE... SOMEWHERE ON BIOSTARS, I THINK

grep --file=file1 file2 > file3 
#using grep, find all lines containing fields in file1 in file2 and print them to a new file, file3
#NOTE: You can add -Fx to grep to make it grep fixed strings and whole lines (i.e., exact matches only)

grep --no-group-separator --no-filename *txt > file2
#Gets rid of the "--" separator between hits in output files (and exludes which file they came from) in all *txt files and prints them to file2.

apt-cache search <search_term>
#Search term for Ubuntu packages that I always seem to forget... 

x=$(wc -l < FILE)
#This makes a variable 'x' that is the number of lines in a file

y=$(grep -c ">" FILE.fasta)
#This makes a variable 'y' that is the number of sequences in a fasta file

Useful loop script:
#!/bin/bash

W=$(wc -l < file)

x=1
while [ $x -le $W ] 
do

      string="sed -n ${x}p file"

        str=$($string)

        var=$(echo $str | awk -F"\t" '{print $1, $2, $3}')
        set -- $var
        c1=$1 #the first variable (column 1 in files)
	c2=$2 #second variable (column 2 in files) This script reads lines one at a time.
	c3=$3 #you get the idea

COMMANDS ${c1} ${c2} ${c3}

x=$(( $x + 1 ))

done

Useful loop for just numbers - for example numbers 13 to 63 in intervals of 10:

for k in $(seq 13 10 63); do
	echo "$k" #commands, replacing $k with each successive number in your series. Also as a style point, indent within loops. Your friends will thank you.
done

